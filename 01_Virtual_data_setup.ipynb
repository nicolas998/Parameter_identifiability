{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-07T15:13:16.690049Z",
     "start_time": "2020-07-07T15:13:05.299040Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No se logra importar deap tools, por lo tanto se deshabilita SimuBasin.Calib_NSGAII\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline \n",
    "from ifis_tools import database_tools as db \n",
    "from ifis_tools import asynch_manager as am \n",
    "from ifis_tools import auxiliar as aux\n",
    "from wmf import wmf\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import os \n",
    "import pylab as pl\n",
    "from string import Template\n",
    "from param_ident import core "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-07T17:24:12.443392Z",
     "start_time": "2020-07-07T17:24:12.440041Z"
    }
   },
   "outputs": [],
   "source": [
    "names = {'south': {'path': 'data/for_hlm/south_skunk/'},\n",
    "        'turkey':{'path':'data/for_hlm/turkey/'}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Watershed setups\n",
    "\n",
    "In this step we will produce the setups of the watersheds making variations of $v_0$ and $\\lambda_1$ for different sizes of sub-watersheds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-07T16:02:37.252535Z",
     "start_time": "2020-07-07T16:02:35.408586Z"
    }
   },
   "outputs": [],
   "source": [
    "#Get the watershed\n",
    "south = am.hlmModel(linkid=272678, ExtraParams=['h_order'])\n",
    "\n",
    "#Temporal rvr to get the topology of the watershed\n",
    "south.write_rvr('data/for_hlm/south_skunk/south_skunk.rvr')\n",
    "topo = south.topo.copy()\n",
    "topo.set_index('link_id', inplace = True)\n",
    "idx = south.Table.index.intersection(topo.index)\n",
    "south.Table['dest'] = topo['id'].loc[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-07T16:10:53.943510Z",
     "start_time": "2020-07-07T16:10:51.460218Z"
    }
   },
   "outputs": [],
   "source": [
    "#Get the watershed\n",
    "turkey = am.hlmModel(linkid=434514, ExtraParams=['h_order'])\n",
    "\n",
    "#Temporal rvr to get the topology of the watershed\n",
    "turkey.write_rvr('data/for_hlm/turkey/turkey.rvr')\n",
    "topo = turkey.topo.copy()\n",
    "topo.set_index('link_id', inplace = True)\n",
    "idx = turkey.Table.index.intersection(topo.index)\n",
    "turkey.Table['dest'] = topo['id'].loc[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-07T16:10:55.213245Z",
     "start_time": "2020-07-07T16:10:55.210308Z"
    }
   },
   "outputs": [],
   "source": [
    "wat = {'south': south, 'turkey': turkey}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtain sub-watersheds at different prun-levels\n",
    "\n",
    "Here we include levels from 7 to 4, then we will produce random values of $v_0$ and $\\lambda_1$ using a cascade approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-07T16:17:22.681258Z",
     "start_time": "2020-07-07T16:11:27.682259Z"
    }
   },
   "outputs": [],
   "source": [
    "# obtain the sub-watersheds for each one (this takes time try not to run it, instead read the data)\n",
    "core.Get_sub_watersheds(wat['south'], 7, 3)\n",
    "core.Get_sub_watersheds(wat['turkey'], 7, 3)\n",
    "# Save to csv files to avoid doing this again.\n",
    "wat['south'].Table.to_csv('data/for_hlm/south_skunk/watershed_table.csv')\n",
    "wat['turkey'].Table.to_csv('data/for_hlm/turkey/watershed_table.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-07T17:17:55.456638Z",
     "start_time": "2020-07-07T17:17:55.426035Z"
    }
   },
   "outputs": [],
   "source": [
    "wat['south'].Table = pd.read_csv('data/for_hlm/south_skunk/watershed_table.csv', index_col=0)\n",
    "wat['turkey'].Table = pd.read_csv('data/for_hlm/turkey/watershed_table.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribute $v_0$ and $\\lambda_1$ using the cascade\n",
    "\n",
    "Produce $v_0$ values for each level "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-07T17:18:14.126009Z",
     "start_time": "2020-07-07T17:18:12.330085Z"
    }
   },
   "outputs": [],
   "source": [
    "for name, seed in zip(['turkey','south'], [[0.15,0.2,0.18,0.25,0.3,0.35,0.4], [0.15,0.3,0.22]]):\n",
    "    for level in [6, 5, 4]:\n",
    "        core.cascade_values(wat[name].Table, 'vo_cas', level, seed)\n",
    "        wat[name].Table.rename(columns = {'vo_cas': 'vo'+str(level)}, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Produce $\\lambda_1$ values for each level "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-07T17:21:55.265811Z",
     "start_time": "2020-07-07T17:21:53.567118Z"
    }
   },
   "outputs": [],
   "source": [
    "for name, seed in zip(['turkey','south'], [[0.19,0.22,0.2,0.22,0.2,0.23,0.3], [0.18,0.23,0.25]]):\n",
    "    for level in [6, 5, 4]:\n",
    "        core.cascade_values(wat[name].Table, 'vo_cas', level, seed)\n",
    "        wat[name].Table.rename(columns = {'vo_cas': 'la'+str(level)}, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the results to a couple of tables with the distributed parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-07T17:25:07.182225Z",
     "start_time": "2020-07-07T17:25:06.282034Z"
    }
   },
   "outputs": [],
   "source": [
    "for name in names.keys():\n",
    "    wat[name].Table.to_csv(names[name]['path']+'water_virtual.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
